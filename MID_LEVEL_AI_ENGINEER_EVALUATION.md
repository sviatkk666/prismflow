# üü° Mid-Level Applied AI Engineer ‚Äî Certification Evaluation

**Status:** ‚¨ú In Progress | ‚úÖ Complete | ‚ùå Not Started

**Date Started:** _______________

**Date Completed:** _______________

---

## üìã How To Use

Mark only when:
- ‚úÖ You **implemented** it
- ‚úÖ You **understand tradeoffs**
- ‚úÖ You can **explain it without guessing**

**Every concept must be applied in code.**

---

## 1Ô∏è‚É£ LLM Foundations (Applied)

### Core Understanding

| Item | Status | Implementation File | Notes |
|------|--------|---------------------|-------|
| Explain what a Transformer does (high-level) | ‚¨ú | | |
| Explain tokens and tokenization | ‚¨ú | | |
| Explain context window limits | ‚¨ú | | |
| Explain temperature vs top_p tradeoffs | ‚¨ú | | |
| Explain why hallucinations happen | ‚¨ú | | |

**Validation:** Can you explain each concept clearly without AI help?
- [ ] Yes, I can explain all 5 concepts
- [ ] Need to review: _______________

---

### API & Output Control

| Item | Status | Implementation File | Test File | Notes |
|------|--------|---------------------|-----------|-------|
| Implement basic chat completion endpoint | ‚¨ú | | | |
| Implement structured JSON output | ‚¨ú | | | |
| Validate output using schema (Zod/Pydantic) | ‚¨ú | | | |
| Handle malformed JSON safely | ‚¨ú | | | |
| Implement streaming response (SSE/WebSocket) | ‚¨ú | | | |
| Add AbortController / cancellation support | ‚¨ú | | | |
| Implement retry with exponential backoff | ‚¨ú | | | |
| Handle API timeouts gracefully | ‚¨ú | | | |

**Validation:** Test each implementation with edge cases.
- [ ] All implementations tested
- [ ] Edge cases handled: _______________

---

### Cost Awareness

| Item | Status | Implementation File | Notes |
|------|--------|---------------------|-------|
| Log input tokens per request | ‚¨ú | | |
| Log output tokens per request | ‚¨ú | | |
| Calculate cost per request | ‚¨ú | | |
| Compare 2 models by cost vs quality | ‚¨ú | | |
| Implement simple response caching | ‚¨ú | | |
| Add max token budget per request | ‚¨ú | | |

**Validation:** Can you estimate cost for 1000 requests?
- [ ] Yes, I can calculate: _______________
- [ ] Need to implement cost tracking

---

## 2Ô∏è‚É£ RAG System (Core Skill)

### Embeddings

| Item | Status | Implementation File | Test File | Notes |
|------|--------|---------------------|-----------|-------|
| Generate embeddings | ‚¨ú | | | |
| Store embeddings with metadata | ‚¨ú | | | |
| Explain cosine similarity | ‚¨ú | | |
| Explain vector dimensionality impact | ‚¨ú | | |
| Compare similarity thresholds experimentally | ‚¨ú | | |

**Validation:** 
- [ ] Can explain why cosine similarity > Euclidean for text
- [ ] Understands dimensionality tradeoffs
- [ ] Has tested similarity thresholds

---

### Chunking

| Item | Status | Implementation File | Test File | Notes |
|------|--------|---------------------|-----------|-------|
| Implement fixed-size chunking | ‚¨ú | | | |
| Implement chunk overlap | ‚¨ú | | | |
| Compare 2 chunk sizes experimentally | ‚¨ú | | | |
| Explain recall vs precision tradeoff | ‚¨ú | | |
| Explain why large chunks reduce precision | ‚¨ú | | |

**Validation:**
- [ ] Can explain recall vs precision tradeoff
- [ ] Understands why overlap improves recall
- [ ] Has experimental results comparing chunk sizes

**Experimental Results:**
```
Chunk Size A: _____ | Recall: _____ | Precision: _____
Chunk Size B: _____ | Recall: _____ | Precision: _____
```

---

### Retrieval

| Item | Status | Implementation File | Test File | Notes |
|------|--------|---------------------|-----------|-------|
| Implement vector similarity search | ‚¨ú | | | |
| Add metadata filtering | ‚¨ú | | | |
| Tune top_k experimentally | ‚¨ú | | | |
| Build retrieval ‚Üí generation pipeline | ‚¨ú | | | |
| Force model to answer only from context | ‚¨ú | | | |
| Add "no answer found" fallback | ‚¨ú | | | |
| Return source citations | ‚¨ú | | | |

**Validation:**
- [ ] Retrieval pipeline works end-to-end
- [ ] Can detect when retrieval fails
- [ ] Citations are accurate

**Top-K Tuning Results:**
```
top_k=3: Precision: _____ | Recall: _____
top_k=5: Precision: _____ | Recall: _____
top_k=10: Precision: _____ | Recall: _____
```

---

## 3Ô∏è‚É£ Basic Agent Capabilities

| Item | Status | Implementation File | Test File | Notes |
|------|--------|---------------------|-----------|-------|
| Implement tool calling | ‚¨ú | | | |
| Define tool schema strictly | ‚¨ú | | | |
| Validate tool arguments | ‚¨ú | | | |
| Execute tools safely | ‚¨ú | | | |
| Prevent infinite tool loops (max step guard) | ‚¨ú | | | |
| Log tool execution steps | ‚¨ú | | | |

**Validation:**
- [ ] Tool calling works reliably
- [ ] Infinite loops prevented
- [ ] All tool executions logged

**Max Step Guard:** Set to: _____ steps

---

## 4Ô∏è‚É£ Production Basics

| Item | Status | Implementation File | Monitoring | Notes |
|------|--------|---------------------|------------|-------|
| Handle rate limits properly | ‚¨ú | | | |
| Handle timeouts | ‚¨ú | | | |
| Log requests and structured errors | ‚¨ú | | | |
| Track latency (p50/p95) | ‚¨ú | | | |
| Track token usage per user | ‚¨ú | | | |
| Basic prompt versioning system | ‚¨ú | | | |

**Validation:**
- [ ] Rate limits handled gracefully
- [ ] Timeouts don't crash system
- [ ] Logging is structured and searchable
- [ ] Latency metrics tracked
- [ ] Token usage per user tracked

**Current Metrics:**
```
p50 Latency: _____ ms
p95 Latency: _____ ms
Average tokens/user/day: _____
```

---

## 5Ô∏è‚É£ Mini Evaluation Layer (Mid-Level Requirement)

| Item | Status | Dataset File | Results File | Notes |
|------|--------|--------------|--------------|-------|
| Create small RAG test dataset (20‚Äì50 Q&A) | ‚¨ú | | | |
| Test retrieval accuracy manually | ‚¨ú | | | |
| Detect when model answers outside context | ‚¨ú | | | |
| Compare two prompt versions | ‚¨ú | | | |

**Test Dataset:**
- Total Questions: _____
- Questions with answers in context: _____
- Questions without answers: _____

**Retrieval Accuracy:**
```
Correct retrievals: _____ / _____ (_____%)
False positives: _____
False negatives: _____
```

**Prompt Comparison:**
```
Version A: Accuracy: _____ | Avg tokens: _____
Version B: Accuracy: _____ | Avg tokens: _____
Winner: _____
```

---

## üß† Mid-Level Validation Questions

**Answer these WITHOUT AI help. Write your answers below:**

### LLM Questions

1. **Why does higher temperature increase hallucination?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

2. **What happens if structured JSON is malformed?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

3. **When should you use streaming?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

4. **When should you NOT use streaming?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

5. **Why do system prompts matter?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

### RAG Questions

6. **Why does chunk overlap improve recall?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

7. **Why does large chunk size reduce precision?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

8. **Why cosine similarity instead of Euclidean?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

9. **What happens if top_k is too large?**
   - Your Answer: 
   - [ ] ‚úÖ Confident | ‚¨ú Need to review

10. **How do you detect retrieval failure?**
    - Your Answer: 
    - [ ] ‚úÖ Confident | ‚¨ú Need to review

### Production Questions

11. **What breaks first at 1k users?**
    - Your Answer: 
    - [ ] ‚úÖ Confident | ‚¨ú Need to review

12. **Why must you log tokens?**
    - Your Answer: 
    - [ ] ‚úÖ Confident | ‚¨ú Need to review

13. **How do you prevent cost explosion?**
    - Your Answer: 
    - [ ] ‚úÖ Confident | ‚¨ú Need to review

14. **What happens if API times out?**
    - Your Answer: 
    - [ ] ‚úÖ Confident | ‚¨ú Need to review

15. **When is RAG better than fine-tuning?**
    - Your Answer: 
    - [ ] ‚úÖ Confident | ‚¨ú Need to review

**Score:** _____ / 15 questions answered confidently

---

## üéØ Passing Criteria Checklist

- [ ] **Implemented everything above** (all items marked ‚úÖ)
- [ ] **Can answer at least 12/15 questions clearly** (Score: _____ / 15)
- [ ] **Can explain architecture end-to-end** (Documentation: _______________)
- [ ] **Can estimate cost roughly before launch** (Example estimate: _______________)

**Architecture Explanation:**
```
[Write a brief explanation of your end-to-end architecture here]
```

**Cost Estimation Example:**
```
Scenario: 1000 users, 10 requests/user/day
Model: _______________
Estimated tokens/day: _______________
Estimated cost/day: _______________
Estimated cost/month: _______________
```

---

## üìù Implementation Notes

### Key Files Created:
- 
- 
- 

### Key Learnings:
- 
- 
- 

### Challenges Overcome:
- 
- 
- 

### Next Steps:
- 
- 
- 

---

## ‚úÖ Final Certification Status

**Overall Status:** ‚¨ú In Progress | ‚úÖ Complete | ‚ùå Not Started

**Completion Date:** _______________

**Reviewer Notes:** _______________

---

## üìö Reference Links

- [ ] LLM API Documentation: _______________
- [ ] Vector Store Documentation: _______________
- [ ] Evaluation Dataset: _______________
- [ ] Architecture Diagram: _______________

---

**Last Updated:** _______________
